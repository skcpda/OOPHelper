{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#Create a Question Component - creates JAVA problems for practicing and evaluates and provides feedback for the same."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to programming_problems_and_feedbacks.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.cohere import Cohere\n",
    "\n",
    "# Initialize Cohere LLM\n",
    "cohere_llm = Cohere(cohere_api_key=\"9rZaWYoS4JsQMcOMZjozd66X0DqbStcRVe8LimVQ\", model=\"command-r-plus\")\n",
    "\n",
    "# List of 10 topics for problem generation\n",
    "topics = [\n",
    "    \"Inheritance and Polymorphism\",\n",
    "    \"Encapsulation and Abstraction\",\n",
    "    \"Interfaces and Abstract Classes\",\n",
    "    \"Collections Framework\",\n",
    "    \"Generics in Java\",\n",
    "    \"Exception Handling\",\n",
    "    \"Lambda Expressions\",\n",
    "    \"Threads and Concurrency\",\n",
    "    \"Design Patterns (e.g., Singleton, Factory)\",\n",
    "    \"Java Stream API\"\n",
    "]\n",
    "\n",
    "# Set up the retrieval function (simply returning the topic for simplicity)\n",
    "def retrieve_relevant_info(query):\n",
    "    \"\"\"\n",
    "    Simulate retrieval of related information (for now, just returning the topic).\n",
    "    \"\"\"\n",
    "    return f\"Relevant information for the topic '{query}'\"\n",
    "\n",
    "# Problem Generator Module (RAG-Enhanced)\n",
    "def generate_problem(topic):\n",
    "    \"\"\"\n",
    "    Generates a detailed Java programming problem in the specified OOP topic, enriched with relevant context.\n",
    "    \"\"\"\n",
    "    # Retrieve related information\n",
    "    relevant_info = retrieve_relevant_info(topic)\n",
    "\n",
    "    # Create the problem prompt enriched with retrieved info\n",
    "    problem_prompt = PromptTemplate(\n",
    "        input_variables=[\"topic\", \"relevant_info\"],\n",
    "        template=(\n",
    "            \"You are a Java programming instructor. Create a detailed programming problem in the area of {topic}. \"\n",
    "            \"Use the following information to help design the problem:\\n{relevant_info}\\n\"\n",
    "            \"Include a clear rubric, deliverables, and requirements. Make the problem challenging yet solvable for students.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Set up the problem generation chain\n",
    "    problem_chain = LLMChain(llm=cohere_llm, prompt=problem_prompt)\n",
    "    return problem_chain.run(topic=topic, relevant_info=relevant_info)\n",
    "\n",
    "# Code Evaluator Module (RAG-Enhanced)\n",
    "def evaluate_code(problem_statement, rubric, student_code):\n",
    "    \"\"\"\n",
    "    Evaluates the student's Java code against the problem statement and rubric, enriched with additional context.\n",
    "    \"\"\"\n",
    "    # Retrieve common mistakes related to the topic for context\n",
    "    common_mistakes = retrieve_relevant_info(\"common mistakes\")\n",
    "\n",
    "    # Create the evaluation prompt enriched with retrieved info\n",
    "    evaluation_prompt = PromptTemplate(\n",
    "        input_variables=[\"problem_statement\", \"rubric\", \"student_code\", \"common_mistakes\"],\n",
    "        template=(\n",
    "            \"You are a Java programming evaluator. The problem statement is as follows:\\n{problem_statement}\\n\\n\"\n",
    "            \"Rubric for evaluation:\\n{rubric}\\n\\n\"\n",
    "            \"The student's code submission is:\\n{student_code}\\n\\n\"\n",
    "            \"Common mistakes for this topic include:\\n{common_mistakes}\\n\\n\"\n",
    "            \"Provide a detailed evaluation based on the rubric, analyzing the correctness, design, and any improvements needed.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Set up the evaluation chain\n",
    "    evaluation_chain = LLMChain(llm=cohere_llm, prompt=evaluation_prompt)\n",
    "    return evaluation_chain.run(problem_statement=problem_statement, rubric=rubric, student_code=student_code, common_mistakes=common_mistakes)\n",
    "\n",
    "# Feedback Generator Module (RAG-Enhanced)\n",
    "def generate_feedback(evaluation):\n",
    "    \"\"\"\n",
    "    Generates constructive feedback for the student based on the evaluation, incorporating relevant context.\n",
    "    \"\"\"\n",
    "    # Retrieve relevant feedback tips (using common mistakes as a placeholder)\n",
    "    relevant_feedback_tips = retrieve_relevant_info(\"common mistakes\")\n",
    "\n",
    "    # Create the feedback prompt enriched with retrieved tips\n",
    "    feedback_prompt = PromptTemplate(\n",
    "        input_variables=[\"evaluation\", \"relevant_feedback_tips\"],\n",
    "        template=(\n",
    "            \"You are a Java programming instructor. Based on the following evaluation, generate constructive feedback \"\n",
    "            \"for the student. Focus on strengths, areas of improvement, and next steps for learning:\\n{evaluation}\\n\"\n",
    "            \"Use the following tips to help guide the student's learning:\\n{relevant_feedback_tips}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Set up the feedback generation chain\n",
    "    feedback_chain = LLMChain(llm=cohere_llm, prompt=feedback_prompt)\n",
    "    return feedback_chain.run(evaluation=evaluation, relevant_feedback_tips=relevant_feedback_tips)\n",
    "\n",
    "# Function to run the entire workflow and write results to a file\n",
    "def gather_data():\n",
    "    # Output file to store results\n",
    "    output_file = \"programming_problems_and_feedbacks.txt\"\n",
    "\n",
    "    # Create a rubric for evaluation\n",
    "    rubric = \"1. Correct use of inheritance (30 points).\\n2. Implementation of polymorphic behavior (30 points).\\n3. Code readability and comments (20 points).\\n4. Test cases and correctness (20 points).\"\n",
    "\n",
    "    # Loop over each topic to generate problem, evaluate code, and provide feedback\n",
    "    with open(output_file, \"w\") as file:\n",
    "        for topic in topics:\n",
    "            # Generate a programming problem\n",
    "            problem = generate_problem(topic)\n",
    "            file.write(f\"Generated Problem for {topic}:\\n{problem}\\n\\n\")\n",
    "\n",
    "            # Placeholder student code (to be evaluated)\n",
    "            student_code = \"\"\"\n",
    "            class Animal {\n",
    "                void sound() {\n",
    "                    System.out.println(\"Animal makes a sound\");\n",
    "                }\n",
    "            }\n",
    "\n",
    "            class Dog extends Animal {\n",
    "                @Override\n",
    "                void sound() {\n",
    "                    System.out.println(\"Dog barks\");\n",
    "                }\n",
    "            }\n",
    "\n",
    "            public class Main {\n",
    "                public static void main(String[] args) {\n",
    "                    Animal obj = new Dog();\n",
    "                    obj.sound();\n",
    "                }\n",
    "            }\n",
    "            \"\"\"\n",
    "\n",
    "            # Evaluate the student's code\n",
    "            evaluation = evaluate_code(problem, rubric, student_code)\n",
    "            file.write(f\"Evaluation for {topic}:\\n{evaluation}\\n\\n\")\n",
    "\n",
    "            # Generate feedback for the student\n",
    "            feedback = generate_feedback(evaluation)\n",
    "            file.write(f\"Feedback for {topic}:\\n{feedback}\\n\\n\")\n",
    "\n",
    "    print(f\"Results have been written to {output_file}\")\n",
    "\n",
    "# Run the data gathering process\n",
    "if __name__ == \"__main__\":\n",
    "    gather_data()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
